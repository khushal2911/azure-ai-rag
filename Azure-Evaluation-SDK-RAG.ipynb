{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dependencies\n",
    "\n",
    "%pip install azure-ai-evaluation\n",
    "\n",
    "%pip install promptflow-azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_openai_endpoint,\n",
    "    \"api_key\": azure_openai_key,\n",
    "    \"azure_deployment\": azure_openai_deployment,\n",
    "}\n",
    "\n",
    "azure_subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "azure_resource_group_name = os.getenv(\"AZURE_RESOURCE_GROUP_NAME\")\n",
    "azure_project_name = os.getenv(\"AZURE_PROJECT_NAME\")\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": azure_subscription_id,\n",
    "    \"resource_group_name\": azure_resource_group_name,\n",
    "    \"project_name\": azure_project_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the first row to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data from a file\n",
    "with open('Data/output/nasabooks-evalset.jsonl', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Assuming the JSON structure is a list of dictionaries and we want the first row\n",
    "first_row = data[0]\n",
    "\n",
    "# Assign values to variables\n",
    "context = first_row['context']\n",
    "query = first_row['query']\n",
    "ground_truth = first_row['ground_truth']\n",
    "response = first_row['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Could not import AIAgentConverter. Please install the dependency with `pip install azure-ai-projects`.\n",
      "[INFO] Could not import SKAgentConverter. Please install the dependency with `pip install semantic-kernel`.\n",
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The RESPONSE is fully grounded and complete, accurately conveying all essential information from the CONTEXT without introducing unsupported details or omitting critical points.', 'groundedness_result': 'pass', 'groundedness_threshold': 3}\n",
      "{'relevance': 5.0, 'gpt_relevance': 5.0, 'relevance_reason': 'The RESPONSE directly answers the QUERY with accurate and complete information about the event that occurred off Vancouver Island in August 2016, making it fully relevant.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n",
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The RESPONSE is coherent and directly addresses the QUERY, providing relevant details and maintaining a logical flow of ideas. It connects the phenomenon to its significance and context, which enhances understanding.', 'coherence_result': 'pass', 'coherence_threshold': 3}\n",
      "{'fluency': 4.0, 'gpt_fluency': 4.0, 'fluency_reason': 'The input Data should get a Score of 4 because it is well-articulated with good control of grammar and a varied vocabulary. The sentences are complex and well-structured, demonstrating coherence and cohesion, with minor errors that do not affect overall understanding.', 'fluency_result': 'pass', 'fluency_threshold': 3}\n",
      "{'similarity': 5.0, 'gpt_similarity': 5.0, 'similarity_result': 'pass', 'similarity_threshold': 3}\n",
      "{'f1_score': 0.48192771084337355, 'f1_result': 'fail', 'f1_threshold': 0.5}\n",
      "{'rouge_precision': 0.3235294117647059, 'rouge_recall': 0.8148148148148148, 'rouge_f1_score': 0.4631578947368421, 'rouge_precision_result': 'fail', 'rouge_recall_result': 'pass', 'rouge_f1_score_result': 'fail', 'rouge_precision_threshold': 0.5, 'rouge_recall_threshold': 0.5, 'rouge_f1_score_threshold': 0.5}\n",
      "{'bleu_score': 0.2039037204136752, 'bleu_result': 'fail', 'bleu_threshold': 0.5}\n",
      "{'meteor_score': 0.5990715616724966, 'meteor_result': 'pass', 'meteor_threshold': 0.5}\n",
      "{'gleu_score': 0.2206896551724138, 'gleu_result': 'fail', 'gleu_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator, \n",
    "    RelevanceEvaluator, \n",
    "    CoherenceEvaluator, \n",
    "    FluencyEvaluator, \n",
    "    SimilarityEvaluator, \n",
    "    F1ScoreEvaluator,\n",
    "    RougeScoreEvaluator, \n",
    "    RougeType,\n",
    "    BleuScoreEvaluator,\n",
    "    MeteorScoreEvaluator,\n",
    "    GleuScoreEvaluator\n",
    "    )\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "groundedness_score = groundedness_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "relevance_score = relevance_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "coherence_score = coherence_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "fluency_score = fluency_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "similarity_score = similarity_eval(\n",
    "    response=response,\n",
    "    query=query,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "f1_eval = F1ScoreEvaluator()\n",
    "f1_score = f1_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "# There are several types of ROUGE metrics: ROUGE_1, ROUGE_2, ROUGE_3, ROUGE_4, ROUGE_5, and ROUGE_L.\n",
    "rouge_eval = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)\n",
    "rouge_score = rouge_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "bleu_eval = BleuScoreEvaluator()\n",
    "bleu_score = bleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "meteor_eval = MeteorScoreEvaluator(\n",
    "    alpha=0.9,\n",
    "    beta=3.0,\n",
    "    gamma=0.5\n",
    ")\n",
    "meteor_score = meteor_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "gleu_eval = GleuScoreEvaluator()\n",
    "gleu_score = gleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(groundedness_score)\n",
    "print(relevance_score)\n",
    "print(coherence_score)\n",
    "print(fluency_score)\n",
    "print(similarity_score)\n",
    "print(f1_score)\n",
    "print(rouge_score)\n",
    "print(bleu_score)\n",
    "print(meteor_score)\n",
    "print(gleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk and Safety Metrics\n",
    "\n",
    "1. Install Azure CLI in Github Codespaces\n",
    "- curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "\n",
    "2. Login with your Azure account \n",
    "- az login --use-device-code\n",
    "- Once you've logged in, select your subscription in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "EvaluationException",
     "evalue": "(UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\nVisit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEvaluationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#azure_ai_project = f\"/subscriptions/{azure_subscription_id}/resourceGroups/{azure_resource_group_name}/providers/Microsoft.CognitiveServices/accounts/{azure_project_name}\"\u001b[39;00m\n\u001b[32m      5\u001b[39m violence_eval = ViolenceEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m violence_score = \u001b[43mviolence_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m hateunfairness_eval = HateUnfairnessEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n\u001b[32m      9\u001b[39m hateunfairness_score = hateunfairness_eval(query=query, response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_content_safety/_violence.py:153\u001b[39m, in \u001b[36mViolenceEvaluator.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=docstring-missing-param\u001b[39;00m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    135\u001b[39m     *args,\n\u001b[32m    136\u001b[39m     **kwargs,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    Evaluate whether violent content is present in your AI system's response.\u001b[39;00m\n\u001b[32m    140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m \u001b[33;03m    :rtype: Union[Dict[str, Union[str, float]], Dict[str, Union[float, Dict[str, List[Union[str, float]]]]]]\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_rai_svc_eval.py:91\u001b[39m, in \u001b[36mRaiServiceEvaluatorBase.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=docstring-missing-param\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     75\u001b[39m     *args,\n\u001b[32m     76\u001b[39m     **kwargs,\n\u001b[32m     77\u001b[39m ):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate either a query and response or a conversation. Must supply either a query AND response,\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    or a conversation, but not both.\u001b[39;00m\n\u001b[32m     80\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[33;03m    :rtype: Union[Dict[str, T], Dict[str, Union[float, Dict[str, List[T]]]]]\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_eval.py:136\u001b[39m, in \u001b[36mEvaluatorBase.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=docstring-missing-param\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    123\u001b[39m     *args,\n\u001b[32m    124\u001b[39m     **kwargs,\n\u001b[32m    125\u001b[39m ) -> Union[DoEvalResult[T_EvalValue], AggregateResult[T_EvalValue]]:\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate a given input. This method serves as a wrapper and is meant to be overridden by child classes for\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03m    one main reason - to overwrite the method headers and docstring to include additional inputs as needed.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m    The actual behavior of this function shouldn't change beyond adding more inputs to the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \u001b[33;03m    :rtype: Union[DoEvalResult[T_EvalValue], AggregateResult[T_EvalValue]]\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masync_run_allowing_running_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_async_evaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/_utils/async_utils.py:94\u001b[39m, in \u001b[36masync_run_allowing_running_loop\u001b[39m\u001b[34m(async_func, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _has_running_loop():\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutorWithContext() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m asyncio.run(_invoke_async_with_sigint_handler(async_func, *args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/_utils/async_utils.py:94\u001b[39m, in \u001b[36masync_run_allowing_running_loop.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _has_running_loop():\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutorWithContext() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m executor.submit(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m).result()\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m asyncio.run(_invoke_async_with_sigint_handler(async_func, *args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/runners.py:194\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._interrupt_count = \u001b[32m0\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interrupt_count > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/asyncio/base_events.py:684\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future.done():\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_eval.py:538\u001b[39m, in \u001b[36mAsyncEvaluatorBase.__call__\u001b[39m\u001b[34m(self, query, response, context, conversation, ground_truth, tool_calls, tool_definitions, messages, retrieval_ground_truth, retrieved_documents, **kwargs)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retrieved_documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    536\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mretrieved_documents\u001b[39m\u001b[33m\"\u001b[39m] = retrieved_documents\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._real_call(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_eval.py:408\u001b[39m, in \u001b[36mEvaluatorBase._real_call\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# Evaluate all inputs.\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m eval_input \u001b[38;5;129;01min\u001b[39;00m eval_input_list:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._do_eval(eval_input)\n\u001b[32m    409\u001b[39m     \u001b[38;5;66;03m# logic to determine threshold pass/fail\u001b[39;00m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_rai_svc_eval.py:105\u001b[39m, in \u001b[36mRaiServiceEvaluatorBase._do_eval\u001b[39m\u001b[34m(self, eval_input)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform the evaluation using the Azure AI RAI service.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03mThe exact evaluation performed is determined by the evaluation metric supplied\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03mby the child class initializer.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m:rtype: Dict\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m eval_input \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m eval_input:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluate_query_response(eval_input)\n\u001b[32m    107\u001b[39m conversation = eval_input.get(\u001b[33m\"\u001b[39m\u001b[33mconversation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluate_conversation(conversation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluators/_common/_base_rai_svc_eval.py:158\u001b[39m, in \u001b[36mRaiServiceEvaluatorBase._evaluate_query_response\u001b[39m\u001b[34m(self, eval_input)\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    150\u001b[39m             message=\u001b[33m\"\u001b[39m\u001b[33mNot implemented\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    151\u001b[39m             internal_message=(\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m             ),\n\u001b[32m    155\u001b[39m         )\n\u001b[32m    156\u001b[39m     input_data[\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m] = context\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m evaluate_with_rai_service(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    159\u001b[39m     metric_name=\u001b[38;5;28mself\u001b[39m._eval_metric,\n\u001b[32m    160\u001b[39m     data=input_data,\n\u001b[32m    161\u001b[39m     project_scope=\u001b[38;5;28mself\u001b[39m._azure_ai_project,\n\u001b[32m    162\u001b[39m     credential=\u001b[38;5;28mself\u001b[39m._credential,\n\u001b[32m    163\u001b[39m     annotation_task=\u001b[38;5;28mself\u001b[39m._get_task(),\n\u001b[32m    164\u001b[39m     evaluator_name=\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m,\n\u001b[32m    165\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_common/rai_service.py:686\u001b[39m, in \u001b[36mevaluate_with_rai_service\u001b[39m\u001b[34m(data, metric_name, project_scope, credential, annotation_task, metric_display_name, evaluator_name, scan_session_id)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    684\u001b[39m     \u001b[38;5;66;03m# Get RAI service URL from discovery service and check service availability\u001b[39;00m\n\u001b[32m    685\u001b[39m     token = \u001b[38;5;28;01mawait\u001b[39;00m fetch_or_reuse_token(credential)\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     rai_svc_url = \u001b[38;5;28;01mawait\u001b[39;00m get_rai_svc_url(project_scope, token)\n\u001b[32m    687\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ensure_service_availability(rai_svc_url, token, annotation_task)\n\u001b[32m    689\u001b[39m     \u001b[38;5;66;03m# Submit annotation request and fetch result\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_common/rai_service.py:593\u001b[39m, in \u001b[36mget_rai_svc_url\u001b[39m\u001b[34m(project_scope, token)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_rai_svc_url\u001b[39m(project_scope: AzureAIProject, token: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the Responsible AI service URL\u001b[39;00m\n\u001b[32m    585\u001b[39m \n\u001b[32m    586\u001b[39m \u001b[33;03m    :param project_scope: The Azure AI project scope details.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    591\u001b[39m \u001b[33;03m    :rtype: str\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     discovery_url = \u001b[38;5;28;01mawait\u001b[39;00m _get_service_discovery_url(azure_ai_project=project_scope, token=token)\n\u001b[32m    594\u001b[39m     subscription_id = project_scope[\u001b[33m\"\u001b[39m\u001b[33msubscription_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    595\u001b[39m     resource_group_name = project_scope[\u001b[33m\"\u001b[39m\u001b[33mresource_group_name\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_common/rai_service.py:571\u001b[39m, in \u001b[36m_get_service_discovery_url\u001b[39m\u001b[34m(azure_ai_project, token)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    566\u001b[39m     msg = (\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to connect to your Azure AI project. Please check if the project scope is configured correctly, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand make sure you have the necessary access permissions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStatus code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    572\u001b[39m         message=msg,\n\u001b[32m    573\u001b[39m         target=ErrorTarget.RAI_CLIENT,\n\u001b[32m    574\u001b[39m         blame=ErrorBlame.USER_ERROR,\n\u001b[32m    575\u001b[39m         category=ErrorCategory.PROJECT_ACCESS_ERROR,\n\u001b[32m    576\u001b[39m         tsg_link=\u001b[33m\"\u001b[39m\u001b[33mhttps://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    577\u001b[39m     )\n\u001b[32m    579\u001b[39m base_url = urlparse(response.json()[\u001b[33m\"\u001b[39m\u001b[33mproperties\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdiscoveryUrl\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url.scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url.netloc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mEvaluationException\u001b[39m: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\nVisit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue."
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import ViolenceEvaluator, HateUnfairnessEvaluator, SelfHarmEvaluator,SexualEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "#azure_ai_project = f\"/subscriptions/{azure_subscription_id}/resourceGroups/{azure_resource_group_name}/providers/Microsoft.CognitiveServices/accounts/{azure_project_name}\"\n",
    "\n",
    "violence_eval = ViolenceEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "violence_score = violence_eval(query=query, response=response)\n",
    "\n",
    "hateunfairness_eval = HateUnfairnessEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "hateunfairness_score = hateunfairness_eval(query=query, response=response)\n",
    "\n",
    "selfharm_eval = SelfHarmEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "selfharm_score = selfharm_eval(query=query, response=response)\n",
    "\n",
    "sexual_eval = SexualEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "sexual_score = sexual_eval(query=query, response=response)\n",
    "\n",
    "print(violence_score)\n",
    "print(hateunfairness_score)\n",
    "print(selfharm_score)\n",
    "print(sexual_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_similarity_20250704_084836_237977, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_similarity_20250704_084836_237977/logs.txt\n",
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_fluency_20250704_084836_237228, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250704_084836_237228/logs.txt\n",
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_coherence_20250704_084836_236885, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250704_084836_236885/logs.txt\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_retrieval_20250704_084836_235729, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_retrieval_20250704_084836_235729/logs.txt\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_relevance_20250704_084836_235973, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250704_084836_235973/logs.txt\n",
      "[2025-07-04 08:48:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:48:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250704_084836_235359, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250704_084836_235359/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:48:39 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:39 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:39 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:40 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 59.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:40 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 59.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:41 +0000 124961664956096 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:41 +0000 124961648170688 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961664956096 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961706919616 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961706919616 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961690134208 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961648170688 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:42 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:48:43 +0000 124961690134208 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:49:43 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:43 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_f1_score_20250704_084836_238992, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_f1_score_20250704_084836_238992/logs.txt\n",
      "[2025-07-04 08:49:44 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:44 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_rouge_score_20250704_084836_239045, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_rouge_score_20250704_084836_239045/logs.txt\n",
      "[2025-07-04 08:49:44 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:44 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_score_20250704_084836_239075, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_score_20250704_084836_239075/logs.txt\n",
      "[2025-07-04 08:49:45 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:45 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_meteor_score_20250704_084836_239100, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_meteor_score_20250704_084836_239100/logs.txt\n",
      "[2025-07-04 08:49:45 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:45 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_gleu_score_20250704_084836_239123, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_gleu_score_20250704_084836_239123/logs.txt\n",
      "[2025-07-04 08:49:45 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:45 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_violence_score_20250704_084836_239146, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_score_20250704_084836_239146/logs.txt\n",
      "[2025-07-04 08:49:46 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:46 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_hateunfairness_score_20250704_084836_239170, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_hateunfairness_score_20250704_084836_239170/logs.txt\n",
      "[2025-07-04 08:49:46 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:46 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_selfharm_score_20250704_084836_239192, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_selfharm_score_20250704_084836_239192/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:49:46 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:49:46 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 5.87 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:49:46 +0000   67620 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:49:47 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:49:47 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_sexual_score_20250704_084836_239213, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_sexual_score_20250704_084836_239213/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:49:47 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:49:47 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 5.94 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.18 seconds. Estimated time for incomplete lines: 6.54 seconds.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.79 seconds. Estimated time for incomplete lines: 1.79 seconds.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:50:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.67 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:50:05 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [0,8,7,1,4,6,3,2,5,9,10,11], exception of index 0: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n",
      "2025-07-04 08:50:06 +0000   67620 execution.bulk     INFO     Finished 1 / 12 lines.\n",
      "2025-07-04 08:50:06 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 19.37 seconds. Estimated time for incomplete lines: 213.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:50:06 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_score_20250704_084836_239146 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Finished 8 / 12 lines.\n",
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.6 seconds. Estimated time for incomplete lines: 10.4 seconds.\n",
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.08 seconds. Estimated time for incomplete lines: 4.16 seconds.\n",
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:50:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.89 seconds. Estimated time for incomplete lines: 1.89 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 3 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 7.19 seconds. Estimated time for incomplete lines: 64.71 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.4 seconds. Estimated time for incomplete lines: 7.2 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.97 seconds. Estimated time for incomplete lines: 1.97 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.78 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [0,7,3,5,1,2,6,4,9,8,10,11], exception of index 0: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.36 seconds. Estimated time for incomplete lines: 7.08 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.93 seconds. Estimated time for incomplete lines: 1.93 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:50:08 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_selfharm_score_20250704_084836_239192 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:50:08 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:50:08 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [2,0,1,3,8,7,5,6,4,10,9,11], exception of index 2: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:50:09 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_hateunfairness_score_20250704_084836_239170 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:50:09 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:50:09 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.83 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:50:09 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [3,6,7,1,5,8,2,0,4,9,10,11], exception of index 3: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:50:09 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_sexual_score_20250704_084836_239213 for more details.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import GroundednessEvaluator, RetrievalEvaluator, RelevanceEvaluator, CoherenceEvaluator, FluencyEvaluator, SimilarityEvaluator, F1ScoreEvaluator\n",
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "from azure.ai.evaluation import ViolenceEvaluator, HateUnfairnessEvaluator, SelfHarmEvaluator,SexualEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "retrieval_eval = RetrievalEvaluator(model_config)\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "f1_eval = F1ScoreEvaluator()\n",
    "rouge_eval = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)\n",
    "bleu_eval = BleuScoreEvaluator()\n",
    "meteor_eval = MeteorScoreEvaluator(\n",
    "    alpha=0.9,\n",
    "    beta=3.0,\n",
    "    gamma=0.5\n",
    ")\n",
    "gleu_eval = GleuScoreEvaluator()\n",
    "violence_eval = ViolenceEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "hateunfairness_eval = HateUnfairnessEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "selfharm_eval = SelfHarmEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "sexual_eval = SexualEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "\n",
    "path = \"Data/output/nasabooks-evalset.jsonl\"\n",
    "\n",
    "result = evaluate(\n",
    "    data=path, # provide your data here\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"retrieval\": retrieval_eval,\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"coherence\": coherence_eval,\n",
    "        \"fluency\": fluency_eval,\n",
    "        \"similarity\":similarity_eval,\n",
    "        \"f1_score\": f1_eval,\n",
    "        \"rouge_score\": rouge_eval,\n",
    "        \"bleu_score\": bleu_eval,\n",
    "        \"meteor_score\": meteor_eval,\n",
    "        \"gleu_score\": gleu_eval,\n",
    "        \"violence_score\": violence_eval,\n",
    "        \"hateunfairness_score\": hateunfairness_eval,\n",
    "        \"selfharm_score\": selfharm_eval,\n",
    "        \"sexual_score\": sexual_eval         \n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"query\": \"${data.query}\",\n",
    "            \"response\": \"${data.response}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "            \"ground_truth\": \"${data.ground_truth}\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(result[\"rows\"])\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Data/output/nasabooks-evalresult.csv', index=False)\n",
    "\n",
    "print(\"DataFrame has been successfully saved to nasabooks-evalresult.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign yourself the Proper role to Track results in Azure AI Foundry\n",
    "\n",
    "1. Get your user ID\n",
    "\n",
    "az ad signed-in-user show --query id --output tsv\n",
    "\n",
    "2. Assign yourself the Storage Blob Data Contributor role. Replace the placeholder text with your subscription ID, resource group, and user ID.\n",
    "\n",
    "az role assignment create --role \"Storage Blob Data Contributor\" --scope /subscriptions/mySubscriptionID/resourceGroups/myResourceGroupName --assignee-principal-type User --assignee-object-id \"user-id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation and Track in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_retrieval_20250704_085436_726597, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_retrieval_20250704_085436_726597/logs.txt\n",
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_coherence_20250704_085436_727476, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250704_085436_727476/logs.txt\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250704_085436_726224, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250704_085436_726224/logs.txt\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_fluency_20250704_085436_727801, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250704_085436_727801/logs.txt\n",
      "[2025-07-04 08:54:36 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_similarity_20250704_085436_728467, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_similarity_20250704_085436_728467/logs.txt\n",
      "[2025-07-04 08:54:36 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_relevance_20250704_085436_726841, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250704_085436_726841/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:54:39 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:39 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:39 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:39 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 60.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:40 +0000 124961639777984 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 59.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:40 +0000 124961639777984 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 59.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961614599872 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 58.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961614599872 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961673348800 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961631385280 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:42 +0000 124961706919616 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:43 +0000 124961656563392 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:43 +0000 124961706919616 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n",
      "2025-07-04 08:54:43 +0000 124961656563392 azure.ai.evaluation._legacy.prompty._prompty WARNING  [0/10] AsyncAzureOpenAI request failed. RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}. Retrying in 57.000000 seconds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_legacy/prompty/_prompty.py\", line 382, in _send_with_retries\n",
      "    response = await client.chat.completions.create(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return await f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/promptflow/tracing/_trace.py\", line 476, in wrapped\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1584, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 57 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:55:41 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:41 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_f1_score_20250704_085436_729120, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_f1_score_20250704_085436_729120/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:55:42 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:55:42 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 5.46 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:55:42 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:42 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_rouge_score_20250704_085436_729166, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_rouge_score_20250704_085436_729166/logs.txt\n",
      "[2025-07-04 08:55:43 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:43 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_score_20250704_085436_729193, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_score_20250704_085436_729193/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:55:43 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:55:43 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 0.01 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:55:43 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:43 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_meteor_score_20250704_085436_729216, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_meteor_score_20250704_085436_729216/logs.txt\n",
      "[2025-07-04 08:55:44 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:44 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_gleu_score_20250704_085436_729238, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_gleu_score_20250704_085436_729238/logs.txt\n",
      "[2025-07-04 08:55:44 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:44 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_violence_score_20250704_085436_729259, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_score_20250704_085436_729259/logs.txt\n",
      "[2025-07-04 08:55:44 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:44 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_hateunfairness_score_20250704_085436_729279, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_hateunfairness_score_20250704_085436_729279/logs.txt\n",
      "[2025-07-04 08:55:45 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:45 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_selfharm_score_20250704_085436_729299, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_selfharm_score_20250704_085436_729299/logs.txt\n",
      "[2025-07-04 08:55:47 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-07-04 08:55:47 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_sexual_score_20250704_085436_729320, log path: /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_sexual_score_20250704_085436_729320/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Finished 8 / 12 lines.\n",
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.52 seconds. Estimated time for incomplete lines: 10.08 seconds.\n",
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.24 seconds. Estimated time for incomplete lines: 6.72 seconds.\n",
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:56:04 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.84 seconds. Estimated time for incomplete lines: 1.84 seconds.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.7 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:56:05 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [4,3,0,2,1,5,6,7,8,10,9,11], exception of index 4: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Finished 3 / 12 lines.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 6.83 seconds. Estimated time for incomplete lines: 61.47 seconds.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.28 seconds. Estimated time for incomplete lines: 6.84 seconds.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.06 seconds. Estimated time for incomplete lines: 4.12 seconds.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:56:05 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.87 seconds. Estimated time for incomplete lines: 1.87 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:56:05 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_score_20250704_085436_729259 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.26 seconds. Estimated time for incomplete lines: 6.78 seconds.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.85 seconds. Estimated time for incomplete lines: 1.85 seconds.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.78 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:56:06 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [2,0,1,4,7,5,6,3,8,9,10,11], exception of index 2: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:56:06 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_hateunfairness_score_20250704_085436_729279 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:56:06 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.76 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:56:06 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [0,1,3,6,2,7,4,5,8,10,9,11], exception of index 0: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Finished 3 / 12 lines.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 6.39 seconds. Estimated time for incomplete lines: 57.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:56:07 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_selfharm_score_20250704_085436_729299 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 2.14 seconds. Estimated time for incomplete lines: 6.42 seconds.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.93 seconds. Estimated time for incomplete lines: 3.86 seconds.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.75 seconds. Estimated time for incomplete lines: 1.75 seconds.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-07-04 08:56:07 +0000   67620 execution.bulk     INFO     Average execution time for completed lines: 1.64 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-07-04 08:56:07 +0000   67620 execution          ERROR    12/12 flow run failed, indexes: [2,1,0,4,5,3,6,7,8,9,10,11], exception of index 2: (UserError) Failed to connect to your Azure AI project. Please check if the project scope is configured correctly, and make sure you have the necessary access permissions. Status code: 404.\n",
      "Visit https://aka.ms/azsdk/python/evaluation/safetyevaluator/troubleshoot to troubleshoot this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:56:08 +0000][promptflow._sdk._orchestrator.run_submitter][WARNING] - 12 out of 12 runs failed in batch run.\n",
      " Please check out /home/codespace/.promptflow/.runs/azure_ai_evaluation_evaluators_sexual_score_20250704_085436_729320 for more details.\n"
     ]
    },
    {
     "ename": "EvaluationException",
     "evalue": "(InternalError) The get 'azure-agentic-openai' workspace request failed with HTTP 404 - (ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/azure-agentic-openai' under resource group 'azure-agentic-ai' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEvaluationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m sexual_eval = SexualEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n\u001b[32m     31\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33mData/output/nasabooks-evalset.jsonl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m result = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# provide your data here\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgroundedness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroundedness_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mretrieval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieval_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelevance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoherence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfluency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfluency_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msimilarity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf1_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrouge_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouge_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbleu_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbleu_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeteor_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeteor_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgleu_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgleu_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mviolence_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mviolence_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhateunfairness_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhateunfairness_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mselfharm_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mselfharm_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msexual_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msexual_eval\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# column mapping\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.ground_truth}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mazure_ai_project\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:808\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    802\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    803\u001b[39m         target=ErrorTarget.EVALUATE,\n\u001b[32m    804\u001b[39m         category=ErrorCategory.FAILED_EXECUTION,\n\u001b[32m    805\u001b[39m         blame=ErrorBlame.SYSTEM_ERROR,\n\u001b[32m    806\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:766\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    764\u001b[39m     user_agent: Optional[\u001b[38;5;28mstr\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33muser_agent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m UserAgentSingleton().add_useragent_product(user_agent) \u001b[38;5;28;01mif\u001b[39;00m user_agent \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluators_and_graders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m            \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    778\u001b[39m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n\u001b[32m    779\u001b[39m     bootstrap_error = (\n\u001b[32m    780\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn attempt has been made to start a new process before the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m        \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcurrent process has finished its bootstrapping phase.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:944\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(evaluators_and_graders, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    942\u001b[39m     studio_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trace_destination:\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m         studio_url = \u001b[43m_log_metrics_and_instance_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_destination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m result_df_dict = results_df.to_dict(\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    949\u001b[39m result: EvaluationResult = {\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m: result_df_dict, \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: metrics, \u001b[33m\"\u001b[39m\u001b[33mstudio_url\u001b[39m\u001b[33m\"\u001b[39m: studio_url}  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_utils.py:235\u001b[39m, in \u001b[36m_log_metrics_and_instance_results\u001b[39m\u001b[34m(metrics, instance_results, trace_destination, run, evaluation_name, name_map, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m ws_triad = extract_workspace_triad_from_trace_provider(trace_destination)\n\u001b[32m    228\u001b[39m management_client = LiteMLClient(\n\u001b[32m    229\u001b[39m     subscription_id=ws_triad.subscription_id,\n\u001b[32m    230\u001b[39m     resource_group=ws_triad.resource_group_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     \u001b[38;5;66;03m# let the client automatically determine the credentials to use\u001b[39;00m\n\u001b[32m    234\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m tracking_uri = \u001b[43mmanagement_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkspace_get_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws_triad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m)\u001b[49m.ml_flow_tracking_uri\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# Adding line_number as index column this is needed by UI to form link to individual instance run\u001b[39;00m\n\u001b[32m    238\u001b[39m instance_results[\u001b[33m\"\u001b[39m\u001b[33mline_number\u001b[39m\u001b[33m\"\u001b[39m] = instance_results.index.values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_azure/_clients.py:159\u001b[39m, in \u001b[36mLiteMLClient.workspace_get_info\u001b[39m\u001b[34m(self, workspace_name)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mworkspace_get_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, workspace_name: \u001b[38;5;28mstr\u001b[39m) -> Workspace:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# https://learn.microsoft.com/rest/api/azureml/workspaces/get?view=rest-azureml-2024-10-01\u001b[39;00m\n\u001b[32m    152\u001b[39m     workspace_response = \u001b[38;5;28mself\u001b[39m._http_client.request(\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         \u001b[38;5;28mself\u001b[39m._generate_path(*PATH_ML_WORKSPACES, workspace_name),\n\u001b[32m    155\u001b[39m         params={QUERY_KEY_API_VERSION: \u001b[38;5;28mself\u001b[39m._api_version},\n\u001b[32m    156\u001b[39m         headers=\u001b[38;5;28mself\u001b[39m._get_headers(),\n\u001b[32m    157\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_throw_on_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m workspace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m     workspace = Workspace.deserialize(workspace_response)\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m workspace\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/azure-ai-rag/.venv/lib/python3.12/site-packages/azure/ai/evaluation/_azure/_clients.py:191\u001b[39m, in \u001b[36mLiteMLClient._throw_on_http_error\u001b[39m\u001b[34m(response, description, valid_status)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (JSONDecodeError, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    192\u001b[39m     message=message,\n\u001b[32m    193\u001b[39m     target=ErrorTarget.EVALUATE,\n\u001b[32m    194\u001b[39m     category=ErrorCategory.FAILED_EXECUTION,\n\u001b[32m    195\u001b[39m     blame=ErrorBlame.SYSTEM_ERROR,\n\u001b[32m    196\u001b[39m )\n",
      "\u001b[31mEvaluationException\u001b[39m: (InternalError) The get 'azure-agentic-openai' workspace request failed with HTTP 404 - (ResourceNotFound) The Resource 'Microsoft.MachineLearningServices/workspaces/azure-agentic-openai' under resource group 'azure-agentic-ai' was not found. For more details please go to https://aka.ms/ARMResourceNotFoundFix"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import GroundednessEvaluator, RetrievalEvaluator, RelevanceEvaluator, CoherenceEvaluator, FluencyEvaluator, SimilarityEvaluator, F1ScoreEvaluator\n",
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "from azure.ai.evaluation import ViolenceEvaluator, HateUnfairnessEvaluator, SelfHarmEvaluator,SexualEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "retrieval_eval = RetrievalEvaluator(model_config)\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "f1_eval = F1ScoreEvaluator()\n",
    "rouge_eval = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)\n",
    "bleu_eval = BleuScoreEvaluator()\n",
    "meteor_eval = MeteorScoreEvaluator(\n",
    "    alpha=0.9,\n",
    "    beta=3.0,\n",
    "    gamma=0.5\n",
    ")\n",
    "gleu_eval = GleuScoreEvaluator()\n",
    "violence_eval = ViolenceEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "hateunfairness_eval = HateUnfairnessEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "selfharm_eval = SelfHarmEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "sexual_eval = SexualEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "\n",
    "path = \"Data/output/nasabooks-evalset.jsonl\"\n",
    "\n",
    "result = evaluate(\n",
    "    data=path, # provide your data here\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"retrieval\": retrieval_eval,\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"coherence\": coherence_eval,\n",
    "        \"fluency\": fluency_eval,\n",
    "        \"similarity\": similarity_eval,\n",
    "        \"f1_score\": f1_eval,\n",
    "        \"rouge_score\": rouge_eval,\n",
    "        \"bleu_score\": bleu_eval,\n",
    "        \"meteor_score\": meteor_eval,\n",
    "        \"gleu_score\": gleu_eval,\n",
    "        \"violence_score\": violence_eval,\n",
    "        \"hateunfairness_score\": hateunfairness_eval,\n",
    "        \"selfharm_score\": selfharm_eval,\n",
    "        \"sexual_score\": sexual_eval \n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"query\": \"${data.query}\",\n",
    "            \"response\": \"${data.response}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "            \"ground_truth\": \"${data.ground_truth}\"\n",
    "        }\n",
    "    },\n",
    "    azure_ai_project = azure_ai_project\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['studio_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Using a Custom Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import load_flow\n",
    "\n",
    "friendliness_eval = load_flow(source=\"friendliness.prompty\", model={\"configuration\": model_config})\n",
    "friendliness_score = friendliness_eval(\n",
    "    query=query,\n",
    "    response=response\n",
    ")\n",
    "print(friendliness_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
